{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Final Project Title by *Your Name\n",
    "\n",
    "## 1. Problem Statement, Motivation, Research Goals: \n",
    "\n",
    "This should be precise and right to the point.\n",
    "\n",
    "## 2. Data Source and Description: \n",
    "\n",
    "Where/how do you get the data?\n",
    "\n",
    "## 3. Literature Review and References: \n",
    "\n",
    "This could include noting any key papers, texts, or websites\n",
    "that you have used to develop your modeling approach, as well as what others have\n",
    "done on this problem in the past. You must properly credit sources.\n",
    "\n",
    "## 4. Preliminary EDA: \n",
    "\n",
    "    a) What is the shape of your data set - how many rows (observations), and how many columns (variables/features)?\n",
    "    b) What are the names of these variables, and its full descriptions?\n",
    "    c) How many numerical variables?\n",
    "    d) How many categorical variables?\n",
    "    e) How many text variables?\n",
    "    f) What variables other than the above are involved?\n",
    "    g) What methods have you used to preprocess/clean/explore the data and why? \n",
    "\n",
    "You will provide related visualizations, summary statistics, and verbal descriptions.\n",
    "\n",
    "## 5. Modeling Process (the main portion): \n",
    "\n",
    "Provide a reproducible modeling process (with all codes and comments, from Data to Models) of fitting \n",
    "\n",
    "     a) an initial baseline (simple) model for comparison \n",
    "     b) a set of competitive feasible models\n",
    "     c) a final model of your best choice\n",
    "\n",
    "## 6. Project Progress, Timeline, and Achievement: \n",
    "\n",
    "Briefly report your progress with a clear timeline (in terms of the number of weeks of the semester) and summarize your project achievement step-by-step that you have made along the way from beginning to end. \n",
    "\n",
    "This timeline will tell how you arrived at your results and powerfully illustrate your efforts in the due process.\n",
    "How well does your model and/or implementation perform? Did you meet your goals? What are the significance of your results?\n",
    "\n",
    "### 7. Conclusions and Possible Future Work: \n",
    "\n",
    "Summarize the strengths and weaknesses of your results, speculate on how you might address these short-comings, and plan for further research directions if given time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Movie classification using plot descriptions by *Your Name\n",
    "\n",
    "## 1. Problem Statement, Motivation, Research Goals: \n",
    "\n",
    "In this project I am going to make a machine learning pipeline from scratch to solve the problem\n",
    "of movie classification using their plot descriptions. I found the dataset by scraping which is a common\n",
    "practice in most data science/machine learning projects.\n",
    "Below are explained some of the data resources I can scrape the data from. Starting from the standard bag-of-words representation I used EDA to identify an\n",
    "appropriate input representation, perform feature engineering on it and find what is a good way\n",
    "to represent movie descriptions. The choice of the model is strongly dependent on the choice of\n",
    "the input representation. \n",
    "\n",
    "Concrete goals:\n",
    "1. Scrape a dataset of about 1000 movies\n",
    "2. Try bag-of-words and word2vec representations for movie descriptions\n",
    "3. Try a naive-bayes classifier and an SVM classifier for both of these text features.\n",
    "4. Answer interesting questions about movie genres and their plots.\n",
    "5. Use conventional machine learning algorithms (not deep nets) to learn a classifier which\n",
    "takes in text as a bag-of-words representation.\n",
    "7. Explore other text representations like word2vec [2] and GloVE [3] word embeddings to\n",
    "see how the right representation affects the performance. This is an especially important\n",
    "lesson for non deep models.\n",
    "8. To be able to take control of the whole machine learning pipeline, and create your own\n",
    "personal version of a project like [1]\n",
    "\n",
    "## 2. Data Source and Description: \n",
    "\n",
    "1. Data sources for labels (movie genres)-\n",
    "- TMDB:Afree, open-source dataset of movie information (https://www.themoviedb.org/?language=en).\n",
    "You will need to create and account to obtain an API key to download information.\n",
    "You can use the library ‘tmdbsimple’ for making easy API calls.\n",
    "- IMDB: The standard database for movie information. You can use the library ‘imdb’\n",
    "to get data from imdb. Now that we know how to get information from TMDB, here’s\n",
    "how we can get information about the same movie from IMDB. This makes it possible\n",
    "for us to combine more information, and get a richer dataset. Due to the di\u000b",
    "erences\n",
    "between the two datasets, you will have to do some cleaning, however both of these\n",
    "datasets are extremely clean and it will be minimal.\n",
    "2. Data sources for movie reviews -\n",
    "- TMDB, IMDB (as above)\n",
    "- Wikipedia: Most movies have a wiki page which contains a \"plot\" section. You can\n",
    "scrape movie description data from here.\n",
    "\n",
    "## 3. Literature Review and References: \n",
    "\n",
    "[1] Spandan Madan. Spandan-Madan/DeepLearningProject: First release of the Deep Learning\n",
    "Project, July 2017.\n",
    "\n",
    "[2] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations\n",
    "of words and phrases and their compositionality. In Advances in neural information\n",
    "processing systems, pages 3111–3119, 2013.\n",
    "\n",
    "[3] Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for\n",
    "word representation. In Proceedings of the 2014 conference on empirical methods in natural language\n",
    "processing (EMNLP), pages 1532–1543, 2014.\n",
    "\n",
    "## 4. Preliminary EDA: \n",
    "\n",
    "    a) What is the shape of your data set - how many rows (observations), and how many columns (variables/features)?\n",
    "    b) What are the names of these variables, and its full descriptions?\n",
    "    c) How many numerical variables?\n",
    "    d) How many categorical variables?\n",
    "    e) How many text variables?\n",
    "    f) What variables other than the above are involved?\n",
    "    g) What methods have you used to preprocess/clean/explore the data and why? \n",
    "\n",
    "You will provide related visualizations, summary statistics, and verbal descriptions.\n",
    "\n",
    "## 5. Modeling Process (the main portion): \n",
    "\n",
    "Provide a reproducible modeling process (with all codes and comments, from Data to Models) of fitting \n",
    "\n",
    "     a) an initial baseline (simple) model for comparison \n",
    "     b) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 - Home Value Predictions in Greater Boston Area by *Your Name\n",
    "\n",
    "## 1. Problem Statement, Motivation, Research Goals: \n",
    "\n",
    "A home is often the largest and most expensive purchase a person makes in his or her lifetime.\n",
    "Ensuring homeowners have a trusted way to monitor this asset is incredibly important. While\n",
    "many individual homebuyers are less sensitive to price forecasts, small errors in price prediction\n",
    "can have systemic negative effects in the economy as a whole. Accurate prediction makes it easier\n",
    "to understand which features would influence the final property price.\n",
    "\n",
    "Real estate prices are very much dependent on factors that are not easy to control. Analyzing\n",
    "broader market conditions and specific property determinants in order to establish how property\n",
    "values may change over the course of time are utterly important. Massive data can be obtained\n",
    "about the current market situation, which demands using powerful machine learning algorithms\n",
    "in order to predict with high precision and in a reasonable time frame.\n",
    "\n",
    "Goal: Build a home valuation algorithm from the ground up, using both, internal and external\n",
    "data sources. Compare final predictions against other popular algorithms estimated values.\n",
    "\n",
    "High-level Project Goals\n",
    "    \n",
    "    Propose a method that effciently handles all the factors in residential real estate. Train/test\n",
    "    your model on 2016/2017 data and report your results.\n",
    "        \n",
    "    Include the interior information about the property into your model (property images). Does\n",
    "    including images improve the predictive power of your model?\n",
    "    \n",
    "    Include exterior information (Google images). How does including Google images a\u000b",
    "ect\n",
    "    your predictions?\n",
    "    \n",
    "    Your final milestone will be predicting the prices based on January 2018 data. Use the above\n",
    "    mentioned steps and derive the best possible combination (features/models) to compare\n",
    "    your predictions with real prices. How precisely will you be able to predict days on the\n",
    "    market and price for every unit?\n",
    "\n",
    "## 2. Data Source and Description: \n",
    "\n",
    "In this project I used a list of real estate properties in a Greater Boston\n",
    "Area. The dataset consists of information about 2016 and 2017 properties and contains a vast\n",
    "amount of features - information about the property, historical data, taxes, exclusie brokers etc.\n",
    "Additionally, you will be provided with the dataset which includes listings from 1/1/2018 until\n",
    "1/31/2018 (approximately 23000 properties) to test your model at the end of the tracking period,\n",
    "that will align with the end of your final project.\n",
    "Additional data challenges\n",
    "\n",
    "I will scrape the historical values on a properties for 2016/2017 data\n",
    "    and compare predictions against both, estimated values and actual sale prices at the time.\n",
    "    \n",
    "In the real estate industry, pictures can easily tell people how the house looks like. I will use the information from provided dataset (street name, street number,\n",
    "    and zip code) to scrape properties descriptions and pictures (some listings have walkthrough\n",
    "    videos that could be taken into an account).\n",
    "\n",
    "For the given house pictures, people can easily have an overall feeling of the house - what is\n",
    "    the construction style, how the neighboring environment looks like etc. Use Google Street\n",
    "    View image API to submit address and scrape Google images about the building (exterior\n",
    "    properties, street quality, neighborhood, near-by attractions).\n",
    "\n",
    "## 3. Literature Review and References: \n",
    "\n",
    "1. Zillow Kaggle Competition: https://www.kaggle.com/c/zillow-prize-1\n",
    "2. UsingPython to scrape Google Street images:https://andrewpwheeler.wordpress.com/2015/12/28/usingpython-\n",
    "to-grab-google-street-view-imagery/\n",
    "3. A. V. Dorogush, A. Gulin, G. Gusev, N. Kazeev, L. Ostroumova Prokhorenkova, A. Vorobev,\n",
    "Fighting biases with dynamic boosting, CoRR, 2017.\n",
    "4. T. Chen and C. Guestrin, XGBoost: A Scalable Tree Boosting System, In Proceedings of the\n",
    "22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining\n",
    "(KDD ’16). ACM, New York, NY, USA, 785-794, 2016.\n",
    "5. Q. You, R. Pang, L. Cao and J. Luo, Image-Based Appraisal of Real Estate Properties, in IEEE\n",
    "Transactions on Multimedia, vol. 19, no. 12, pp. 2751-2759, 2017.\n",
    "\n",
    "## 4. Preliminary EDA: \n",
    "\n",
    "    a) What is the shape of your data set - how many rows (observations), and how many columns (variables/features)?\n",
    "    b) What are the names of these variables, and its full descriptions?\n",
    "    c) How many numerical variables?\n",
    "    d) How many categorical variables?\n",
    "    e) How many text variables?\n",
    "    f) What variables other than the above are involved?\n",
    "    g) What methods have you used to preprocess/clean/explore the data and why? \n",
    "\n",
    "You will provide related visualizations, summary statistics, and verbal descriptions.\n",
    "\n",
    "## 5. Modeling Process (the main portion): \n",
    "\n",
    "Provide a reproducible modeling process (with all codes and comments, from Data to Models) of fitting \n",
    "\n",
    "     a) an initial baseline (simple) model for comparison \n",
    "     b) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Cryptocurrency Market Analysis and Prediction by *Your Name\n",
    "\n",
    "## 1. Problem Statement, Motivation, Research Goals: \n",
    "\n",
    "Cryptocurrencies such as Bitcoin, Ethereum, etc. generated significant attention in 2017. Cryptocurrencies\n",
    "have significant volalility as there is rampant speculation. Given the high variance in\n",
    "prices, can data science methods be used to model the market dynamics?\n",
    "\n",
    "Can an effective trading strategy be found? Try exploring different strategies.\n",
    "We are looking for a demonstration of sound data science principles\n",
    "here.\n",
    "\n",
    "Market Analysis Given there is now option trading on certain cryptocurrencies, is it possible to\n",
    "create a volatility index for cryptocurrencies such as VIX? Is variance of this market infinite\n",
    "and therefore not predictable? Are there any rational reasons for investing that you can\n",
    "justify using data science?\n",
    "Arbitrage Given the number of different currencies and different markets, how effcient is the\n",
    "market? Are there arbitrage opportunities? Can evidence be found of arbitrage?\n",
    "Your own find some other area that a team would like to explore. This could include using CNN’s\n",
    "to analyze up-to-the-minute market plots to find interesting patterns, analysis of the ICO\n",
    "market, etc. Discuss with your TF before choosing a new direction. I will need to justify\n",
    "access to data, complexity, and expected hypotheses.\n",
    "\n",
    "Project goal\n",
    "Apply well-reasoned data science methods to analyze a specific aspect of the cryptocurrency space.\n",
    "There are many examples of simple attempts to throw deep learning models at cryptocurrency\n",
    "historical prices. The vast majority lack scientific rigor and analysis of variance. We are looking\n",
    "for you to go beyond these feeble attempts and take a rigorous approach to determine if this is a\n",
    "solvable problem and give justifications to your hypotheses.\n",
    "\n",
    "High-level project goals\n",
    "1. Analyze the trading data using traditional and novel market analysis metrics.\n",
    "2. Build a series of models, including ideally a deep learning model such a RNN, to predict a\n",
    "specifc aspect such as pricing, volatility, market volume\n",
    "3. Choose the best model, justify your choice, and describe strengths and limitations of the\n",
    "chosen model.\n",
    "\n",
    "\n",
    "## 2. Data Source and Description: \n",
    "\n",
    "### a) Kaggle Cryptocurrency Historical Prices\n",
    "www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory\n",
    "- Historical daily pricing data of the most common cryptocurrencies (Bitcoin, Ethereum,\n",
    "Ripple, etc.). Includes open, high, low, close, volume, market cap.\n",
    "- Data up to November 2017\n",
    "- Can integrate other sources, such as Blockchain Info or Etherscan\n",
    "\n",
    "### b) Bitcoin Trades to the minute\n",
    "www.kaggle.com/mczielinski/bitcoin-historical-data\n",
    "- Minute by minute trading data on Bitcoin from various exchanges.\n",
    "- Data from January 2012 until January 2018.\n",
    "- Useful for trading strategies and perhaps arbitrage, but not recommended for long\n",
    "term market dynamics.\n",
    "\n",
    "### c) Bitcoin Blockchain in BigQuery\n",
    "cloud.google.com/blog/big-data/2018/02/bitcoin-in-bigquery-blockchain-analytics-on-publicdata\n",
    "- All historical bitcoin transactions in an easy to query, very fast format using Google Cloud\n",
    "\n",
    "## 3. Literature Review and References: \n",
    "1. Financial forecasting with probabilistic programming and Pyro\n",
    "2. Predicting Cryptocurrency PricesWith Deep Learning\n",
    "3. Learning to trade Cryptocurrencies with Reinforcement Learning\n",
    "\n",
    "## 4. Preliminary EDA: \n",
    "\n",
    "    a) What is the shape of your data set - how many rows (observations), and how many columns (variables/features)?\n",
    "    b) What are the names of these variables, and its full descriptions?\n",
    "    c) How many numerical variables?\n",
    "    d) How many categorical variables?\n",
    "    e) How many text variables?\n",
    "    f) What variables other than the above are involved?\n",
    "    g) What methods have you used to preprocess/clean/explore the data and why? \n",
    "\n",
    "You will provide related visualizations, summary statistics, and verbal descriptions.\n",
    "\n",
    "## 5. Modeling Process (the main portion): \n",
    "\n",
    "Provide a reproducible modeling process (with all codes and comments, from Data to Models) of fitting \n",
    "\n",
    "     a) an initial baseline (simple) model for comparison \n",
    "     b) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Example 4 - Predicting Success on Third Downs in NFL Football by *Your Name\n",
    "\n",
    "## 1. Problem Statement, Motivation, Research Goals: \n",
    "\n",
    "     Third down and long is the toughest situation for any offensive coordinator in the NFL. –\n",
    "     Matthew Stafford\n",
    "\n",
    "Success in the NFL often comes down to consistent achievement in key but common situations.\n",
    "One of the most important tactical elements in NFL football is being able to convert a third down\n",
    "into a first down (or better). Several analytic studies have explored strategic considerations on\n",
    "fourth downs, but we are not aware of studies that have addressed success on third downs. In\n",
    "most third down plays (but not all), a team’s offense tries to achieve a first-down conversion; if\n",
    "they fail, their options on fourth down are limited and much of the time the team will punt the ball.\n",
    "\n",
    "The goal of this project is to obtain play-by-play NFL data to examine, predict, and summarize\n",
    "success on third downs. Situational features of the game are certain to play an important role: The\n",
    "number of yards short of the first down marker, where is the offense on the field, current score of\n",
    "the game, time remaining in the game, identity of key players such as the quarterback, running\n",
    "back, and so on. What types of plays are run are what are their success probabilities? What advice\n",
    "can you give coaches based on your conclusions?\n",
    "\n",
    "Key Challenges: Scraping data, wrangling data, visualization, statistical modeling, machine learning.\n",
    "\n",
    "## 2. Data Source and Description: \n",
    "\n",
    "You will be required to collect play-by-play data for NFL games. Some resources for play-by-play\n",
    "data include\n",
    "\n",
    "\u000f https://www.pro-football-reference.com/boxscores/201709100was.htm#all_pbp\n",
    "\n",
    "\u000f http://www.espn.com/nfl/playbyplay?gameId=400951760\n",
    "\n",
    "\u000f https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016/data\n",
    "\n",
    "It may help to use the nflscrapR R package. Details of the package may be found at https:\n",
    "//github.com/maksimhorowitz/nflscrapR. A short example of its use can be found at https:\n",
    "//www.r-bloggers.com/nfl-series/.\n",
    "\n",
    "## 3. Literature Review and References: \n",
    " \n",
    "1. Berri, D. J., & Burke, B. (2012). Measuring productivity of NFL players. In The economics of\n",
    "the National Football League (pp. 137-158). Springer New York.\n",
    "2. Fokoue, E., & Foehrenbach, D. (2013). A Statistical Data Mining Approach to Determining\n",
    "the Factors that Distinguish Championship Caliber Teams in the National Football League.\n",
    "3. Onwuegbuzie, A. J. (2000). Is Defense or O\u000b",
    "ense More Important for Professional Football\n",
    "Teams? A Replication Study Using Data from the 1998-1999 Regular Football Season.\n",
    "Perceptual and motor skills, 90(2), 640-648.\n",
    "4. Clevenson, M. L., &Wright, J. (2009). Go For It: What to consider when making fourth-down\n",
    "decisions. Chance, 22(1), 34-41.\n",
    "\n",
    "## 4. Preliminary EDA: \n",
    "\n",
    "    a) What is the shape of your data set - how many rows (observations), and how many columns (variables/features)?\n",
    "    b) What are the names of these variables, and its full descriptions?\n",
    "    c) How many numerical variables?\n",
    "    d) How many categorical variables?\n",
    "    e) How many text variables?\n",
    "    f) What variables other than the above are involved?\n",
    "    g) What methods have you used to preprocess/clean/explore the data and why? \n",
    "\n",
    "You will provide related visualizations, summary statistics, and verbal descriptions.\n",
    "\n",
    "## 5. Modeling Process (the main portion): \n",
    "\n",
    "Provide a reproducible modeling process (with all codes and comments, from Data to Models) of fitting \n",
    "\n",
    "     a) an initial baseline (simple) model for comparison \n",
    "     b) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
